{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jennylin331431/JSC270_NLP_Project/blob/main/Part_II_Having_fun_with_NLP_using_the_Twitter_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAMqEjsANA3E"
      },
      "source": [
        "# Retrieve Data Set "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy as tw\n",
        "import csv #Import csv"
      ],
      "metadata": {
        "id": "DbYDeHf0kiFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7JLgIpw8HtP"
      },
      "outputs": [],
      "source": [
        "# Use credentials to authorize access\n",
        "auth = tw.OAuthHandler('JpudYifLLJpILP2l5kVoHDj9s', 'Qdwdl6llsSoMVsVukeAcoR4RgkAdf5xdk4fVPiAakrPH8x7u0J')\n",
        "auth.set_access_token('1501628668040384513-mWlZCtzphRpCXCpT4DzCU5y9SgnpeW','9z7q0ePlmXH1wmos6mJg6rESj1evx8Euh4B48pUgriWZC')\n",
        "api = tw.API(auth, wait_on_rate_limit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##convert data into a csv file\n"
      ],
      "metadata": {
        "id": "mbRsQjoJlBlV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJd-hZL1qhm3"
      },
      "outputs": [],
      "source": [
        "\n",
        "#define our search word\n",
        "search_words = '#ukraine'\n",
        "\n",
        "#filter out tweets with retweets, images, links\n",
        "search_with_filter = search_words + \" -filter:retweets\" + \" -filter:images\" +  \" -filter:links\"\n",
        "\n",
        "#starting date of the data wanted\n",
        "date_since = \"2022-03-18\"\n",
        "\n",
        "# Open/create a file to append data to\n",
        "csvFile = open('1000.csv', 'a')\n",
        "\n",
        "#Use csv writer\n",
        "csvWriter = csv.writer(csvFile)\n",
        "tweets = tw.Cursor(api.search,\n",
        "              q=search_with_filter,\n",
        "              lang=\"en\",\n",
        "              since=date_since,\n",
        "              exclude_replies=True, #exclude replies\n",
        "              trim_user=True,\n",
        "              until = '2022-03-20',\n",
        "              tweet_mode='extended',\n",
        "              ).items(1200) #1000 tweets\n",
        "\n",
        "#put all tweets into a list\n",
        "a = [tweet for tweet in tweets]\n",
        "\n",
        "#iterate through the tweets to write into csv file\n",
        "for tweet in a:\n",
        "    # Write a row to the CSV file. I use encode UTF-8\n",
        "    csvWriter.writerow([tweet.created_at, tweet.full_text.encode('utf-8')])\n",
        "    print (tweet.created_at, tweet.full_text)\n",
        "csvFile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkeHfpgR8OQZ"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "D3O2HURl8POy",
        "outputId": "5159259a-401a-471d-ccdc-8dad7a4842a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bed5b65a-6411-49f7-9f24-d71026e2cb82\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bed5b65a-6411-49f7-9f24-d71026e2cb82\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving result.csv to result.csv\n"
          ]
        }
      ],
      "source": [
        "# Import data\n",
        "from google.colab import files\n",
        "data = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "A6uI0p0LsMGq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zss7RxOR8a0C"
      },
      "outputs": [],
      "source": [
        "#read csv file\n",
        "data = pd.read_csv(io.BytesIO(data['result.csv']), sep = ',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first 10 rows of data\n",
        "data['Tweet'].head(10)"
      ],
      "metadata": {
        "id": "BnODbT-Aqd0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce7cbf8-e59b-45ef-bc64-e4e5940a1ba2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    b\"@anneapplebaum We'll see. E.U. usually moves...\n",
              "1    b'According to #NATO, treaties matter more tha...\n",
              "2    b'@JoeBiden let #ukraine down like #Afghanista...\n",
              "3    b'@Geof17773624 Consumer impact has been but a...\n",
              "4    b'The medias BS in getting Tuchel to join Man ...\n",
              "5    b'- #Russia invasion of #Ukraine has overshado...\n",
              "6    b\"The #russianbomb hasn't hit my house yet, bu...\n",
              "7    b\"@VP Who made you VP, you don't even know tha...\n",
              "8    b\"@JuliaHB1 @BorisJohnson A more accurate comp...\n",
              "9    b'Sorry #Ukraine, you are not part of our club...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE6s-AFx8q9t",
        "outputId": "26e88cbb-ff2d-422b-d94a-da32dc86a186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "0    786\n",
              "1    413\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#the counts of each Sentiment within the dataset\n",
        "data.value_counts('Sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0lGUF5uN9WzY"
      },
      "outputs": [],
      "source": [
        "#set seed to avoid different train/test splits every time\n",
        "np.random.seed(100)\n",
        "#split the data set into train and test by 30/70\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Tweet'], data['Sentiment'], test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mo7aZUtI92mK"
      },
      "outputs": [],
      "source": [
        "# Make training and testing datasets\n",
        "train_data = pd.DataFrame({\"Tweet\": X_train, \"Sentiment\": y_train})\n",
        "test_data = pd.DataFrame({\"Tweet\": X_test, \"Sentiment\": y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B4yk-g4mESj",
        "outputId": "f1592b7f-7992-4f46-ac61-45d5383626cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "0    550\n",
              "1    289\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#count sentiments in train data\n",
        "train_data.value_counts('Sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQJ_SDTEmIuc",
        "outputId": "fa4dc4ba-8904-4d6c-a5d6-340cdaacea36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "0    236\n",
              "1    124\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#count sentiments in test data\n",
        "test_data.value_counts('Sentiment')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vltRhlKii9T"
      },
      "source": [
        "## Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports \n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem.porter import *\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "4I-KeRMhmGYU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMM58MWbkgPw",
        "outputId": "8b3cb2a8-a578-4b7a-b346-c5ac91d580a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# Tokenize data\n",
        "# Download the tokenizer\n",
        "nltk.download('punkt')\n",
        "\n",
        "#tokenize dataset\n",
        "def tokenize(data, column_to_tokenize, column_save_tokens):\n",
        "  data[column_save_tokens] = data[column_to_tokenize].apply(nltk.word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ytDYj_mZik3Q"
      },
      "outputs": [],
      "source": [
        "##### Remove URL tokens #####\n",
        "def remove_URL_tokens(data, column):\n",
        "  tokens_no_URL = []\n",
        "  # Create a list of lists with what we want\n",
        "  for row in data[column]:\n",
        "    tokens_no_URL.append([re.sub(r'http\\S+','', t) for t in row])\n",
        "  # add the new info to our df\n",
        "  data[column] = tokens_no_URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FoddwGulir7V"
      },
      "outputs": [],
      "source": [
        "##### Convert tokens into lowercase ####\n",
        "def convert_lowercase(data, column):\n",
        "  lowercase_tokens = []\n",
        "  # Create a list of lists with what we want\n",
        "  for row in data[column]:\n",
        "    lowercase_tokens.append([t.lower() for t in row])\n",
        "  # add the new info to our df\n",
        "  data[column] = lowercase_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GRUetExfitdn"
      },
      "outputs": [],
      "source": [
        "##### Remove punctuation and special characters #####\n",
        "def remove_special_char(data, column):\n",
        "  tokens_no_punct = []\n",
        "  # Create a list of lists with what we want\n",
        "  for row in data[column]:\n",
        "    tokens_no_punct.append([re.sub('[^\\w\\s]','', t) for t in row])\n",
        "  # add the new info to our df\n",
        "  data[column] = tokens_no_punct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_SZjGd3fivF2"
      },
      "outputs": [],
      "source": [
        "##### Remove empty tokens #####\n",
        "def remove_empty_tokens(data, column):\n",
        "  tokens_no_empty = []\n",
        "  for row in data[column]:\n",
        "    tokens_no_empty.append([w for w in row if (w != '')])\n",
        "  data[column] = tokens_no_empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LPpUtALoizkj"
      },
      "outputs": [],
      "source": [
        "#### Stemming tokens ####\n",
        "\n",
        "#use PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_tokens(data, column):\n",
        "  stemmed_tokens = []\n",
        "  for row in data[column]:\n",
        "    stemmed_tokens.append([stemmer.stem(t) for t in row])\n",
        "\n",
        "  data[column] = stemmed_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O53hX_wOkUE0",
        "outputId": "75f70d11-759d-48c1-cba6-677a9a858189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#### Lemmatize the Dataset ####\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(data, column):\n",
        "  lem_tokens = []\n",
        "  for row in data[column]:\n",
        "    lem_tokens.append([lemmatizer.lemmatize(t) for t in row])\n",
        "  data[column] = lem_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xRpNe7yi11v",
        "outputId": "e27258c2-be5e-4d58-93cd-e01877b0924a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "##### Remove Stopwords #####\n",
        "nltk.download('stopwords')\n",
        "sw = stopwords.words('english')[:100]\n",
        "# Remove stopwords\n",
        "\n",
        "def remove_stopwords(data, column):\n",
        "  tokens_no_sw = []\n",
        "  for row in data[column]:\n",
        "    tokens_no_sw.append([w for w in row if w not in sw])\n",
        "  # Add column to df\n",
        "  data[column] = tokens_no_sw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HAJolzRlTbW"
      },
      "source": [
        "## EDA using preprocessing functions on training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "s_kF6flJlWYb"
      },
      "outputs": [],
      "source": [
        "#tokenize train data\n",
        "tokenize(train_data, 'Tweet', 'tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvZ8fTBcmUQ_",
        "outputId": "692c1419-8c4b-42c6-e763-0a817b28d6f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "522     [b, ', @, Hromadske, Russians, using, chemical...\n",
              "213     [b, ', #, Russian, aviation, has, significantl...\n",
              "120     [b, ', @, lesiavasylenko, How, do, you, know, ...\n",
              "916     [b, ', @, PaulaChertok, @, JuliaDavisNews, @, ...\n",
              "1066    [b'1/, The, Prosecutor, of, the, International...\n",
              "1116    [b'Knowledgeable, panel, @, JoyAnnReid, Very, ...\n",
              "72      [b, ', @, Alex_Uhtz, @, JeroenLoos1, @, Sorrel...\n",
              "820     [b, ', #, JoeBiden, you, can, help, clean, up,...\n",
              "746     [b, ', @, rnz_news, The, only, reason, they, w...\n",
              "715     [b'Privileged, to, be, sharing, the, same, hot...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#view tokens of first 10 rows in train data\n",
        "train_data['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shmCOh85mkn4",
        "outputId": "1064eab7-a6c0-4f5c-fc35-839c8e5f5d5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "522     [b, ', @, Hromadske, Russians, using, chemical...\n",
              "213     [b, ', #, Russian, aviation, has, significantl...\n",
              "120     [b, ', @, lesiavasylenko, How, do, you, know, ...\n",
              "916     [b, ', @, PaulaChertok, @, JuliaDavisNews, @, ...\n",
              "1066    [b'1/, The, Prosecutor, of, the, International...\n",
              "1116    [b'Knowledgeable, panel, @, JoyAnnReid, Very, ...\n",
              "72      [b, ', @, Alex_Uhtz, @, JeroenLoos1, @, Sorrel...\n",
              "820     [b, ', #, JoeBiden, you, can, help, clean, up,...\n",
              "746     [b, ', @, rnz_news, The, only, reason, they, w...\n",
              "715     [b'Privileged, to, be, sharing, the, same, hot...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#remove URL tokens from train data\n",
        "remove_URL_tokens(train_data, 'tokens')\n",
        "train_data['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qy8Id_lpmu5",
        "outputId": "75ec63b3-e7b4-4e86-83a1-4e9b85dfdd86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "522     [b, ', @, hromadske, russians, using, chemical...\n",
              "213     [b, ', #, russian, aviation, has, significantl...\n",
              "120     [b, ', @, lesiavasylenko, how, do, you, know, ...\n",
              "916     [b, ', @, paulachertok, @, juliadavisnews, @, ...\n",
              "1066    [b'1/, the, prosecutor, of, the, international...\n",
              "1116    [b'knowledgeable, panel, @, joyannreid, very, ...\n",
              "72      [b, ', @, alex_uhtz, @, jeroenloos1, @, sorrel...\n",
              "820     [b, ', #, joebiden, you, can, help, clean, up,...\n",
              "746     [b, ', @, rnz_news, the, only, reason, they, w...\n",
              "715     [b'privileged, to, be, sharing, the, same, hot...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#convert all tokens to lowercases in train data\n",
        "convert_lowercase(train_data, 'tokens')\n",
        "train_data['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrzqD6xTpt6V",
        "outputId": "c61c1b06-0dab-40eb-ec97-81bb76c45b6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "522     [b, hromadske, russians, using, chemical, weap...\n",
              "213     [b, russian, aviation, has, significantly, red...\n",
              "120     [b, lesiavasylenko, how, do, you, know, they, ...\n",
              "916     [b, paulachertok, juliadavisnews, acosta, russ...\n",
              "1066    [b1, the, prosecutor, of, the, international, ...\n",
              "1116    [bknowledgeable, panel, joyannreid, very, inte...\n",
              "72      [b, alex_uhtz, jeroenloos1, sorrelz, avalaina,...\n",
              "820     [b, joebiden, you, can, help, clean, up, the, ...\n",
              "746     [b, rnz_news, the, only, reason, they, would, ...\n",
              "715     [bprivileged, to, be, sharing, the, same, hote...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#remove special characters from train data\n",
        "remove_special_char(train_data, 'tokens')\n",
        "#remove empty tokens from train data\n",
        "remove_empty_tokens(train_data, 'tokens')\n",
        "train_data['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SylFKjIp0N0",
        "outputId": "da61d393-2b49-4767-bc1b-a0a55ca26479"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "522     [b, hromadske, russian, using, chemical, weapo...\n",
              "213     [b, russian, aviation, ha, significantly, redu...\n",
              "120     [b, lesiavasylenko, how, do, you, know, they, ...\n",
              "916     [b, paulachertok, juliadavisnews, acosta, russ...\n",
              "1066    [b1, the, prosecutor, of, the, international, ...\n",
              "1116    [bknowledgeable, panel, joyannreid, very, inte...\n",
              "72      [b, alex_uhtz, jeroenloos1, sorrelz, avalaina,...\n",
              "820     [b, joebiden, you, can, help, clean, up, the, ...\n",
              "746     [b, rnz_news, the, only, reason, they, would, ...\n",
              "715     [bprivileged, to, be, sharing, the, same, hote...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#lemmatize tokens in train data\n",
        "lemmatize_tokens(train_data, 'tokens')\n",
        "train_data['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyk1hpi8p6kJ",
        "outputId": "515def5a-d68f-4c0d-f2cd-57f2ef0a6927"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "522     [b, hromadske, russian, using, chemical, weapo...\n",
              "213     [b, russian, aviation, ha, significantly, redu...\n",
              "120     [b, lesiavasylenko, how, know, havnt, many, ru...\n",
              "916     [b, paulachertok, juliadavisnews, acosta, russ...\n",
              "1066    [b1, prosecutor, international, criminal, cour...\n",
              "1116    [bknowledgeable, panel, joyannreid, very, inte...\n",
              "72      [b, alex_uhtz, jeroenloos1, sorrelz, avalaina,...\n",
              "820     [b, joebiden, can, help, clean, mess, help, ma...\n",
              "746     [b, rnz_news, only, reason, would, use, ukrain...\n",
              "715     [bprivileged, sharing, same, hotel, ukraine, d...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#remove stopwords in train data\n",
        "remove_stopwords(train_data, 'tokens')\n",
        "train_data['tokens'].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4myvsL4rb5u"
      },
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebQqx1Xy6I5V"
      },
      "outputs": [],
      "source": [
        "## Lemmatized train_data\n",
        "# can try changing the functions applied to the data and see how the result changes\n",
        "tokenize(train_data, 'Tweet', 'lem_tokens')\n",
        "remove_URL_tokens(train_data, 'lem_tokens')\n",
        "convert_lowercase(train_data, 'lem_tokens')\n",
        "remove_special_char(train_data, 'lem_tokens')\n",
        "remove_empty_tokens(train_data, 'lem_tokens')\n",
        "lemmatize_tokens(train_data, 'lem_tokens')\n",
        "remove_stopwords(train_data, 'lem_tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9QoQmZM6OWN"
      },
      "outputs": [],
      "source": [
        "## Stemmed train_data\n",
        "# can try changing the functions applied to the data and see how the result changes\n",
        "tokenize(train_data, 'Tweet', 'stem_tokens')\n",
        "remove_URL_tokens(train_data, 'stem_tokens')\n",
        "convert_lowercase(train_data, 'stem_tokens')\n",
        "remove_special_char(train_data, 'stem_tokens')\n",
        "remove_empty_tokens(train_data, 'stem_tokens')\n",
        "stem_tokens(train_data, 'stem_tokens')\n",
        "remove_stopwords(train_data, 'stem_tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6JT4Wqh4cMC"
      },
      "source": [
        "### Word cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFob3JhqsPyd"
      },
      "outputs": [],
      "source": [
        "# concatenate tokens (helper function for make_word_cloud)\n",
        "def string_tokens(data, column):\n",
        "    collect = ''\n",
        "    for tokens in data[column]:\n",
        "      for t in tokens:\n",
        "        collect = collect + ' ' + t\n",
        "    return collect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6WPElw4t6Pj"
      },
      "outputs": [],
      "source": [
        "# change the value to black (helper function for make_word_cloud)\n",
        "def black_color_func(word, font_size, position,orientation,random_state=None, **kwargs): \n",
        "  return(\"hsl(0,100%, 1%)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import matplotlib.pyplot as plt \n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "igPg7ZteneL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV6czwjd3saL"
      },
      "outputs": [],
      "source": [
        "## https://towardsdatascience.com/how-to-make-word-clouds-in-python-that-dont-suck-86518cdcb61f\n",
        "\n",
        "# Make word cloud and display it\n",
        "def make_word_cloud(data, column):\n",
        "  words = string_tokens(data, column)\n",
        "  wordcloud = WordCloud(background_color=\"white\", width=3000, height=2000, max_words=500).generate(words)\n",
        "  wordcloud.recolor(color_func = black_color_func)\n",
        "  plt.figure(figsize=[15,10])\n",
        "  plt.imshow(wordcloud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZhxs3t6hbd"
      },
      "source": [
        "#### Word cloud for lemmatized data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um9umM_M4OIj"
      },
      "outputs": [],
      "source": [
        "#for non-supporting tweets\n",
        "make_word_cloud(train_data[train_data['Sentiment'] == 0], 'lem_tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQBP9z634TD3"
      },
      "outputs": [],
      "source": [
        "#for supporing tweets\n",
        "make_word_cloud(train_data[train_data['Sentiment'] == 1], 'lem_tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3gl0I2x6qgB"
      },
      "source": [
        "#### Word cloud for stemmed tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7MZsNVw6l_t"
      },
      "outputs": [],
      "source": [
        "#for non-supporing tweets\n",
        "make_word_cloud(train_data[train_data['Sentiment'] == 0], 'stem_tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kEb27vy6qGp"
      },
      "outputs": [],
      "source": [
        "#for supporing tweets\n",
        "make_word_cloud(train_data[train_data['Sentiment'] == 0], 'stem_tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WHZHhYejcSL"
      },
      "source": [
        "## apply the preprocessing functions to data for the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9DXe1l7-i32I"
      },
      "outputs": [],
      "source": [
        "# can try changing the functions applied to the data and see how the result changes\n",
        "\n",
        "#apply preprocessing functions to train data\n",
        "tokenize(train_data, 'Tweet', 'tokens')\n",
        "remove_URL_tokens(train_data, 'tokens')\n",
        "convert_lowercase(train_data, 'tokens')\n",
        "remove_special_char(train_data, 'tokens')\n",
        "remove_empty_tokens(train_data, 'tokens')\n",
        "lemmatize_tokens(train_data, 'tokens')\n",
        "remove_stopwords(train_data, 'tokens')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "njUdQrOik8ps"
      },
      "outputs": [],
      "source": [
        "# can try changing the functions applied to the data and see how the result changes\n",
        "\n",
        "#apply preprocessing functions to test data\n",
        "tokenize(test_data, 'Tweet', 'tokens')\n",
        "remove_URL_tokens(test_data, 'tokens')\n",
        "convert_lowercase(test_data, 'tokens')\n",
        "remove_special_char(test_data, 'tokens')\n",
        "remove_empty_tokens(test_data, 'tokens')\n",
        "lemmatize_tokens(test_data, 'tokens')\n",
        "remove_stopwords(test_data, 'tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWCGdd-_M8v1"
      },
      "source": [
        "# Model Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA_wVtXhDm6f"
      },
      "source": [
        "### Use of CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-0BK0AgDolw",
        "outputId": "512660ce-4009-4be9-e7d1-531afe5dc4d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [2 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Length of vocabulary:  1000\n",
            "{'b': 85, 'russian': 708, 'using': 913, 'chemical': 154, 'weapon': 943, 'now': 579, 'ukraine': 879, 'aviation': 80, 'ha': 368, 'ukrainian': 891, 'reported': 695, 'air': 30, 'force': 327, 'day': 213, 'defense': 222, 'shot': 748, 'three': 845, 'lesiavasylenko': 473, 'how': 395, 'know': 454, 'many': 505, 'all': 33, 'hate': 375, 'violence': 923, 'happening': 374, 'russia': 706, 'commits': 175, 'warcrimes': 934, 'democracy': 226, 'must': 541, 'united': 901, 'save': 722, 'world': 969, 'peacekeeping': 618, 'mission': 528, 'there': 835, 'no': 570, 'other': 605, 'way': 941, 'child': 157, 'woman': 962, 'journalist': 441, 'need': 551, 'u': 876, 'government': 363, 'move': 538, 'rhetoric': 698, 'action': 20, 'standwithukraine': 783, 'stopputin': 792, 'noflyzoneua': 573, 'international': 423, 'criminal': 206, 'court': 203, 'any': 56, 'member': 516, 'public': 661, 'may': 509, 'possible': 639, 'war': 933, 'crime': 205, 'humanity': 399, 'committed': 176, 'very': 918, 'interesting': 422, 'current': 208, 'conflict': 191, 'putinisawarcriminal': 665, 'avalaina': 77, 'find': 317, 'most': 536, 'support': 809, 'invasion': 426, 'come': 174, 'people': 620, 'live': 483, 'totalitarian': 859, 'state': 786, 'land': 460, 'run': 704, 'military': 523, 'not': 577, 'just': 442, 'worth': 970, 'joebiden': 436, 'can': 147, 'help': 381, 'make': 502, 'giving': 357, 'only': 599, 'reason': 682, 'would': 971, 'use': 911, 'defence': 218, 'thing': 837, 'also': 42, 'more': 535, 'missile': 527, 'putinhitler': 664, 'sharing': 746, 'same': 719, 'face': 294, 'such': 804, 'home': 389, 'won': 963, 'stay': 787, 'kid': 447, 'death': 216, 'dangerous': 212, 'food': 326, 'water': 940, 'please': 628, 'keep': 444, 'fighting': 314, 'nt': 581, 'give': 355, 're': 675, 'right': 700, 'behind': 98, 'putin': 663, 'go': 358, 'hell': 380, 'bad': 89, 'guy': 367, 'urgent': 907, 'time': 849, 'running': 705, 'josepborrellf': 440, 'potus': 642, 'olafscholz': 594, 'ba': 87, 's': 713, 'attention': 76, 'turned': 873, '500daysoftigraygenocide': 13, 'unleashed': 903, 'ethiopian': 271, 'eritrean': 269, 'unimpeded': 897, 'xe2x80x9cinjustice': 985, 'anywhere': 59, 'threat': 844, 'justice': 443, 'everywhere': 283, 'when': 950, 'will': 957, 'compassion': 185, 'extend': 292, 'innocent': 417, 'civilian': 165, 'tigray': 846, 'icc': 404, 'unocha': 905, 'officer': 591, 'wa': 929, 'involved': 427, 'terrorist': 828, 'group': 366, 'work': 966, 'nationalist': 546, 'nn': 567, 'someone': 770, 'fuck': 339, 'johnson': 437, 'person': 622, 'pm': 629, 'selfish': 734, 'corrupt': 196, 'palestine': 611, 'yemen': 992, 'syria': 814, 'afghanistan': 24, 'country': 202, 'twitter': 875, 'posting': 640, 'video': 922, 'showing': 751, 'suffering': 805, 'ppl': 645, 'company': 180, 'policy': 632, 'case': 150, 'everything': 282, 'allowed': 37, 'n': 542, 'tigraygenocide': 848, 'mrsorokaa': 539, 'win': 958, 'xf0x9fx87xbaxf0x9fx87xa6': 987, 'thread': 843, 'why': 955, 'thatxe2x80x99s': 832, 'going': 360, 'almost': 39, 'month': 533, '100': 2, 'killed': 451, '3': 9, 'million': 524, 'refugee': 686, 'lost': 494, 'city': 164, 'where': 951, 'visit': 924, 'every': 280, 'few': 310, 'away': 82, 'left': 472, 'die': 235, 'nothing': 578, 'want': 931, 'talk': 819, 'peace': 617, 'so': 767, 'foxnews': 332, 'saying': 724, 'border': 119, 'open': 600, 'quiet': 670, 'see': 731, 'kyivindependent': 459, 'maybe': 510, 'china': 158, 'some': 769, 'sanction': 720, 'pay': 616, 'chinese': 159, 'good': 361, 'eu': 272, 'might': 520, 'start': 784, 'finance': 316, 'bundeskanzler': 135, 'least': 468, 'close': 168, 'sky': 763, 'life': 476, 'european': 275, 'value': 914, 'one': 598, 'freedom': 334, 'putinswar': 666, 'zelensky': 995, 'needed': 552, 'cia': 162, 'soldier': 768, 'europe': 274, 'played': 627, 'big': 108, 'role': 703, 'helping': 382, 'buy': 137, 'gas': 346, 'destroyed': 231, 'killing': 452, 'eu_commission': 273, 'get': 353, 'could': 200, 'donxe2x80x99t': 251, 'let': 474, 'nthis': 582, 'real': 680, 'elonmusk': 261, 'told': 853, 'dont': 250, 'side': 753, 'say': 723, 'nobody': 571, 'regime': 689, 'today': 851, 'ally': 38, 'turn': 872, 'eye': 293, 'bputin': 124, 'struggle': 802, 'canxe2x80x99t': 148, 'fly': 323, 'zone': 999, 'leader': 466, 'around': 66, 'fear': 304, 'ca': 142, 'political': 633, 'position': 638, 'family': 300, 'overshadowed': 607, 'atrocity': 72, 'manmade': 504, 'famine': 301, 'tigrayans': 847, 'fallen': 299, 'victim': 920, '500days': 12, 'ic': 403, 'speak': 775, 'stand': 781, 'vickyford': 919, 'ukun_newyork': 893, 'niinisto': 566, 'nazi': 548, 'complete': 186, 'jew': 435, 'break': 125, 'strong': 801, 'tank': 821, 'ball': 90, 'school': 725, 'r': 673, 'amp': 49, 'like': 477, 'nato': 547, 'equipment': 268, 'message': 519, 'send': 736, 'far': 302, 'borisjohnson': 121, 'back': 88, 'hand': 370, 'taking': 818, 'watch': 939, 'night': 565, 'promise': 656, 'w': 928, 'love': 496, 'lord': 491, 'law': 464, 'near': 550, 'bit': 113, 'cover': 204, 'provide': 660, 'written': 972, 'neighbour': 554, 'population': 636, 'prevent': 651, 'friend': 337, 'enemy': 265, 'xd0x9cxd0xb0xd1x80xd1x96xd1x83xd0xbfxd0xbexd0xbbxd1x8c': 980, 'xd0x9axd0xb8xd1x97xd0xb2': 978, 'xd0x9bxd1x8cxd0xb2xd1x96xd0xb2': 979, 'xd1x85xd0xb0xd1x80xd0xbaxd1x96xd0xb2n': 982, 'xd0xa3xd0xbaxd1x80xd0xb0xd1x97xd0xbdxd0xb0': 981, 'closetheskyn': 169, 'noflyzone': 572, 'nuclear': 583, 'terrorism': 827, 'warn': 937, 'america': 46, 'losing': 493, 'breaking': 126, 'heart': 379, 'bthe': 131, 'armed': 63, 'believe': 101, 'offensive': 589, 'completely': 187, 'biden': 105, 'zelenskyyua': 997, 'stepping': 788, 'humanitarian': 398, 'aid': 29, 'bwhen': 140, 'took': 855, 'men': 518, 'too': 854, 'put': 662, 'top': 856, 'ukrainerussianwar': 886, 'iaponomarenko': 402, 'money': 532, '10': 1, 'dollar': 247, 'head': 377, 'ukrainewar': 889, 'weakness': 942, 'saturday': 721, 'thought': 841, 'quote': 672, 'still': 789, 'business': 136, 'ukrainen': 883, 'boycottrussia': 123, 'stopwarinukraine': 795, 'continues': 193, 'focus': 324, 'silently': 756, 'recognise': 684, 'hold': 387, 'abiyahmedali': 15, 'account': 17, 'bring': 128, 'end': 264, 'ungeneva': 896, 'blood': 116, 'holocaustmemorialday': 388, 'mlk': 530, 'grenfelltower': 365, 'blacklivesmatter': 115, 'bidenharris': 106, 'oprahmeghanharry': 602, 'reparationsnow': 692, 'kyiv': 458, 'mariupol': 507, 'zelenskyy': 996, 'kharkiv': 445, 'odessa': 587, 'kramatorsk': 455, 'think': 838, 'should': 749, 'tried': 865, 'stop': 790, 'oil': 593, 'atleast': 71, 'five': 320, 'usa': 910, 'importing': 409, 'year': 991, 'everchoose': 279, 'drive': 252, 'monthpls': 534, 'spread': 778, 'word': 965, 'asap': 68, 'even': 276, 'ridiculous': 699, 'comparison': 184, 'fight': 312, 'human': 397, 'own': 608, 'nnwe': 569, 'small': 766, 'better': 103, 'b031922': 86, 'dod': 244, 'thejointstaff': 834, 'secdef': 728, 'us_eucom': 908, 'odnigov': 588, 'whnsc': 953, 'us_stratcom': 909, 'used': 912, 'hypersonic': 401, 'destroy': 230, 'warehouse': 935, 'ammunition': 48, 'confirms': 190, 'comparing': 183, 'uk': 878, 'brexit': 127, 'order': 604, 'yet': 994, 'care': 149, 'much': 540, 'bombing': 118, 'etc': 270, 'ask': 69, 'doesnxe2x80x99t': 246, 'doe': 245, 'bwe': 138, 'offer': 590, 'expert': 290, 'pres': 647, 'never': 556, 'un': 894, 'half': 369, 'arrive': 67, 'recent': 683, 'foreign': 329, 'federation': 305, 'than': 829, '27': 8, 'citizen': 163, 'said': 718, 'general': 348, 'national': 545, 'control': 194, 'claim': 166, 'tragedy': 863, 'bi': 104, 'ssu': 779, 'minister': 526, '30': 10, 'economy': 257, 'hannaliubakova': 371, 'powerful': 644, 'indeed': 411, 'm': 498, 'wife': 956, 'another': 53, 'wrong': 973, 'beautiful': 96, 'ready': 679, 'leaving': 470, 'example': 286, 'warinukraine': 936, 'march': 506, 'concern': 188, 've': 916, 'resident': 697, 'unitedstates': 902, 'vp': 927, 'knew': 453, 'election': 260, 'sending': 737, 'trump': 867, 'unite': 900, 'simply': 758, 'poland': 631, 'germany': 352, 'bif': 107, 'vote': 925, '1': 0, 'russiaukrainewar': 712, 'bwhat': 139, 'else': 262, 'happen': 372, 'understand': 895, 'supportukraine': 811, 'fully': 341, 'mean': 512, 'corruption': 197, 'voted': 926, 'answer': 54, 'always': 44, 'hope': 391, 'leave': 469, 'hrw': 396, 'line': 480, 'medium': 514, 'economic': 256, 'pressure': 649, 'direct': 240, 'join': 439, 'act': 19, 'ever': 278, 'seeing': 732, 'innasovsun': 416, 'happened': 373, 'well': 946, 'little': 482, 'lot': 495, 'report': 694, 'launch': 463, 'attack': 73, 'soon': 773, 'seems': 733, 'here': 383, 'folk': 325, 'oligarch': 597, 'mcfaul': 511, 'arm': 62, 'destroying': 232, 'israel': 428, 'document': 243, 'exactly': 285, 'victory': 921, 'kiev': 449, 'unit': 899, 'building': 133, 'several': 742, 'rocket': 702, 'system': 815, 'west': 947, 'long': 487, '20': 5, 'wwii': 976, 'wwiii': 977, 'ixe2x80x99m': 433, 'sure': 812, 'itxe2x80x99s': 432, 'become': 97, 'istandwithukraine': 431, 'xf0x9fx87xbaxf0x9fx87xb8': 988, 'street': 799, '2': 4, 'prez': 652, 'zelenskyyxf0x9fx87xbaxf0x9fx87xa6': 998, 'each': 255, '2000': 6, 'xf0x9fx87xb7xf0x9fx87xba': 986, 'chance': 152, 'avenge': 78, 'dead': 214, 'silent': 755, 'difference': 236, 'planned': 626, 'militant': 521, 'azov': 84, 'battalion': 92, 'facility': 295, 'diplomatic': 239, 'western': 948, 'evident': 284, 'demonstrated': 228, 'towards': 861, 'matter': 508, 'others': 606, 'chief': 156, 'staff': 780, 'including': 410, 'enough': 267, 'wheat': 949, 'product': 654, 'next': 560, 'russiaukraine': 710, 'ukrainerussiawar': 887, 'ukraineunderattack': 888, 'wsj': 974, 'wo': 961, 'idea': 405, 'olex_scherba': 596, 'armenia': 64, 'supporting': 810, 'express': 291, 'official': 592, 'clear': 167, 'party': 614, 'bbcnews': 93, 'bwhy': 141, 'wanted': 932, 'port': 637, 'black': 114, 'sea': 726, 'crisis': 207, 'both': 122, 'camp': 146, 'property': 658, 'place': 623, 'demand': 224, 'le': 465, 'bomb': 117, 'interest': 421, 'already': 41, 'independent': 413, 'alliance': 35, 'meanwhile': 513, 'nnbut': 568, 'compared': 182, 'clown': 170, 'protect': 659, 'russianinvasion': 709, 'free': 333, 'made': 499, 'belarusian': 100, 'embassy': 263, 'last': 461, 'quite': 671, 'really': 681, 'color': 172, 'latest': 462, 'operation': 601, 'hostage': 392, 'house': 394, 'try': 869, 'president': 648, 'week': 945, 'perhaps': 621, 'lviv': 497, 'along': 40, 'meeting': 515, 'led': 471, 'bthere': 132, 'great': 364, 'nation': 544, 'poor': 635, 'super': 807, 'ambassador': 45, 'lie': 475, 'tory': 857, 'disgrace': 242, 'shameful': 745, 'community': 179, 'desire': 229, 'take': 816, 'call': 144, 'russiainvadedukraine': 707, 'stopputinnow': 793, 'unmanned': 904, 'aerial': 23, 'vehicle': 917, 'fighter': 313, 'flag': 321, 'ufclondon': 877, 'instead': 419, '4': 11, 'expand': 288, 'refuse': 687, 'safe': 716, 'thousand': 842, 'occupied': 586, 'donetsk': 249, 'administration': 22, 'daily': 210, 'imagine': 406, 'feel': 306, 'wonder': 964, 'though': 840, 'forget': 330, 'communication': 177, 'caa': 143, 'strength': 800, '8th': 14, 'combat': 173, 'bbut': 95, 'got': 362, 'xi': 990, 'game': 345, 'cost': 199, 'problem': 653, 'defending': 221, 'invaded': 425, 'corridor': 195, 'continue': 192, 'direction': 241, 'sumy': 806, 'territory': 826, 'started': 785, 'sonn': 772, 'energy': 266, 'democrat': 227, 'attempt': 75, 'look': 489, 'aggression': 27, 'whole': 954, 'beside': 102, 'bigger': 109, 'pentagon': 619, 'simple': 757, 'kill': 450, 'georgia': 350, 'nrep': 580, 'arizona': 61, 'north': 576, 'thanks': 831, 'full': 340, 'either': 258, 'stoprussia': 794, 'trying': 870, 'mother': 537, 'fate': 303, 'news': 558, 'longer': 488, 'putinwarcriminal': 668, 'thank': 830, 'tweet': 874, 'anders_aslund': 50, 'belarus': 99, 'event': 277, 'excuse': 287, 'survival': 813, 'animal': 51, 'situation': 762, 'unprovoked': 906, 'strange': 797, 'potential': 641, 'danger': 211, 'anyone': 57, 'warning': 938, 'expect': 289, 'cossack': 198, 'total': 858, 'different': 237, 'old': 595, 'part': 613, 'anything': 58, 'allow': 36, 'defend': 219, '13': 3, 'hour': 393, 'majority': 501, 'xd8xb1xd9x88xd8xb3xd9x8axd8xa7': 983, 'working': 968, 'invade': 424, 'shit': 747, 'fund': 343, 'special': 776, 'option': 603, 'baltic': 91, 'red': 685, 'alert': 32, 'siren': 761, 'min': 525, 'russiaukraineconflict': 711, 'ww3': 975, 'festival': 309, 'india': 414, 'fact': 297, 'bbcworld': 94, 'cohort': 171, 'hatecrimes': 376, 'az': 83, 'lil': 479, 'kremlin': 456, 'kidnapped': 448, 'independence': 412, 'forced': 328, 'modern': 531, 'communist': 178, 'valuestactics': 915, 'demilitarized': 225, 'honest': 390, 'xf0x9fx87xbaxf0x9fx87xb8attorneygeneral': 989, 'kremlinrussia_e': 457, 'wearing': 944, 'reach': 676, 'inside': 418, 'something': 771, 'heard': 378, 'show': 750, 'freeukraine': 335, 'remember': 691, 'deborahmeaden': 217, 'sad': 715, 'compare': 181, 'boris': 120, 'field': 311, 'britain': 129, 'supply': 808, 'ukrainecrisis': 881, 'nft': 561, 'since': 759, 'deal': 215, 'intel': 420, 'republic': 696, 'anti': 55, 'first': 319, 'ukrainexf0x9fx87xbaxf0x9fx87xa6': 890, 'signed': 754, 'future': 344, 'stupid': 803, 'forward': 331, 'french': 336, 'gave': 347, 'johnsonout54': 438, 'nice': 563, 'bso': 130, 'living': 484, 'normal': 575, 'paper': 612, 'looking': 490, 'fellow': 308, 'shame': 744, 'stopped': 791, 'hunterbidenslaptop': 400, 'within': 959, 'll': 485, 'together': 852, 'plan': 624, 'alleged': 34, 'targeted': 823, 'selling': 735, 'fire': 318, 'cause': 151, 'feeling': 307, 'pain': 610, 'security': 730, 'ukrainerussia': 885, 'totally': 860, 'putinwarcrimes': 667, 'local': 486, 'american': 47, 'ni': 562, 'istandwithrussia': 430, 'anonymous': 52, 'genocide': 349, 'lose': 492, 'history': 384, 'hit': 385, 'ukraineinvasion': 882, 'slavaukraini': 764, 'fun': 342, 'reached': 677, 'kherson': 446, 'worker': 967, 'shut': 752, 'across': 18, 'target': 822, 'jessel36': 434, 'truth': 868, 'aka': 31, 'without': 960, 'plane': 625, 'railway': 674, 'tell': 824, '24': 7, 'german': 351, 'nwho': 585, 'ukraineconflict': 880, 'choice': 160, 'getting': 354, 's400': 714, 'point': 630, 'theater': 833, 'didnxe2x80x99t': 234, 'front': 338, 'theyxe2x80x99re': 836, 'taken': 817, 'hitler': 386, 'given': 356, 'due': 253, 'read': 678, 'council': 201, 'called': 145, 'troop': 866, 'turkey': 871, 'talking': 820, 'finally': 315, 'immediately': 407, 'past': 615, 'aggressor': 28, 'preparing': 646, 'army': 65, 'africa': 25, 'african': 26, 'bin': 112, 'likely': 478, 'service': 741, 'regarding': 688, 'attacked': 74, 'town': 862, 'information': 415, 'union': 898, 'god': 359, 'sense': 738, 'nor': 574, 'trend': 864, 'membership': 517, 'speech': 777, 'alsoxc2xa0': 43, 'elected': 259, 'facing': 296, 'delaying': 223, 'militarily': 522, 'done': 248, 'standing': 782, 'secblinken': 727, 'maid': 500, 'thinking': 839, 'safety': 717, 'propaganda': 657, 'xe2x80x9c': 984, 'cut': 209, 'bukovina': 134, 'fled': 322, 'average': 79, 'sleep': 765, 'single': 760, 'soul': 774, 'ukrainenn': 884, 'na': 543, 'neighbor': 553, 'adamkinzinger': 21, 'question': 669, 'new': 557, 'wake': 930, 'mistake': 529, 'important': 408, 'defended': 220, 'everyone': 281, 'project': 655, 'leadership': 467, 'telling': 825, 'seriously': 740, 'diplomat': 238, 'istandwithputin': 429, 'naziukraine': 549, 'approaching': 60, 'man': 503, 'condemnation': 189, 'nickiminaj': 564, 'asking': 70, 'second': 729, 'biggest': 110, 'repeat': 693, 'yes': 993, 'channel': 153, 'region': 690, 'accept': 16, 'serious': 739, 'pretty': 650, 'strangely': 798, 'literally': 481, 'billion': 111, 'fair': 298, 'destruction': 233, 'christ': 161, 'ukranian': 892, 'neutral': 555, 'chernihiv': 155, 'aware': 81, 'story': 796, 'power': 643, 'nuke': 584, 'rise': 701, 'dying': 254, 'shall': 743, 'nex': 559, 'p': 609, 'white': 952, 'poo': 634, 'tinxe2x80x99s': 850}\n",
            "\n",
            "Great is located at row:  364\n"
          ]
        }
      ],
      "source": [
        "#import\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Separate labels from features, converting to numpy arrays\n",
        "X_train, y_train = train_data['tokens'].to_numpy(), train_data['Sentiment'].to_numpy()\n",
        "X_test, y_test = test_data['tokens'].to_numpy(), test_data['Sentiment'].to_numpy()\n",
        "\n",
        "#overriding function\n",
        "def override_fcn(doc):\n",
        "  # We expect a list of tokens as input\n",
        "  return doc\n",
        "\n",
        "# Count Vectorizer\n",
        "count_vec = CountVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer= override_fcn,\n",
        "    preprocessor= override_fcn,\n",
        "    token_pattern= None,\n",
        "    max_features = 1000)\n",
        "\n",
        "# Fit training data using CountVectorizer\n",
        "counts_train = count_vec.fit_transform(X_train)\n",
        "print(counts_train.toarray())\n",
        "\n",
        "# Fit testing data using CountVectorizer\n",
        "counts_test = count_vec.transform(X_test)\n",
        "print(counts_test.toarray())\n",
        "\n",
        "# Print the names of each of the features (1000 total))\n",
        "print(\"Length of vocabulary: \", len(count_vec.vocabulary_))\n",
        "# Print this mapping as dictionary\n",
        "print(count_vec.vocabulary_)\n",
        "\n",
        "## Which row represents 'great'\n",
        "print('\\nGreat is located at row: ',count_vec.vocabulary_['great'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP6Jb-8XnaGw",
        "outputId": "9062a746-eabf-4307-dae8-df46d4abad8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes: 0.7138888888888889\n",
            "Training accuracy with simple Naive Bayes: 0.8545887961859356\n"
          ]
        }
      ],
      "source": [
        "#imports \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# fit the Naive Bayes model to our training data\n",
        "nb = MultinomialNB()\n",
        "# Fit model to training data (default alpha = 1 has Laplace smoothing)\n",
        "nb.fit(counts_train.toarray(), y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_preds_test = nb.predict(counts_test.toarray())\n",
        "\n",
        "# Predict on train data\n",
        "y_preds_train = nb.predict(counts_train.toarray())\n",
        "\n",
        "#Print test/train accuracy\n",
        "print('Test accuracy with simple Naive Bayes:',accuracy_score(y_test,y_preds_test))\n",
        "print('Training accuracy with simple Naive Bayes:',accuracy_score(y_train,y_preds_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KfMX6FtmX8wz"
      },
      "outputs": [],
      "source": [
        "#function to print out the top n most probable words for the class\n",
        "def most_probable_word_for_class(vectorizer, classifier, classlabel, n):\n",
        "    labelid = list(classifier.classes_).index(classlabel)\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "    topn = sorted(zip(classifier.feature_count_[classlabel][:], feature_names))[-n:]\n",
        "    for coef, feat in topn:\n",
        "        print(\"word: \", feat, \"count: \", coef)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19IL3MYxX81F",
        "outputId": "704a2a81-6fdf-4306-a10b-2413b2848aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ten most probable words for non-support/neutral Ukraine tweets\n",
            "word:  victim count:  74.0\n",
            "word:  n count:  90.0\n",
            "word:  ha count:  96.0\n",
            "word:  not count:  101.0\n",
            "word:  war count:  107.0\n",
            "word:  russian count:  113.0\n",
            "word:  s count:  116.0\n",
            "word:  russia count:  212.0\n",
            "word:  b count:  328.0\n",
            "word:  ukraine count:  592.0\n",
            "Ten most probable words for support Ukraine tweets\n",
            "word:  world count:  43.0\n",
            "word:  all count:  44.0\n",
            "word:  will count:  50.0\n",
            "word:  s count:  52.0\n",
            "word:  not count:  60.0\n",
            "word:  war count:  66.0\n",
            "word:  putin count:  72.0\n",
            "word:  russia count:  97.0\n",
            "word:  b count:  194.0\n",
            "word:  ukraine count:  319.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#Print 10 most probable words for non-supporting tweets\n",
        "print(\"Ten most probable words for non-support/neutral Ukraine tweets\")\n",
        "most_probable_word_for_class(count_vec, nb, 0, n=10)\n",
        "\n",
        "#Print 10 most probable words for supporting tweets\n",
        "print(\"Ten most probable words for support Ukraine tweets\")\n",
        "most_probable_word_for_class(count_vec, nb, 1, n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use of TF-IDF-Vectorizer"
      ],
      "metadata": {
        "id": "Fxw5W2H4jBZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Note that smoothing is done by default\n",
        "tfidf = TfidfTransformer()\n",
        "\n",
        "#fit transoform the train data set\n",
        "tfs_train = tfidf.fit_transform(counts_train)\n",
        "#fit transoform the test data set\n",
        "tfs_test = tfidf.transform(counts_test)\n",
        "\n",
        "# Use the TFIDF counts for modelling\n",
        "X_train = tfs_train.toarray()\n",
        "X_test = tfs_test.toarray()"
      ],
      "metadata": {
        "id": "gaEjv53YjLiY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the Naive Bayes model to our training data\n",
        "nb = MultinomialNB()\n",
        "# Fit model to training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_preds_test = nb.predict(X_test)\n",
        "\n",
        "# Predict on train data\n",
        "y_preds_train = nb.predict(X_train)\n",
        "\n",
        "#print test/train accuracy\n",
        "print('Test accuracy with simple Naive Bayes:',accuracy_score(y_test,y_preds_test))\n",
        "print('Training accuracy with simple Naive Bayes:',accuracy_score(y_train,y_preds_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnGyw3sBjha8",
        "outputId": "8c1fccfc-b0c6-49e8-9071-3fcb9869bd64"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes: 0.7305555555555555\n",
            "Training accuracy with simple Naive Bayes: 0.8438617401668653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling Trial with Stem Tokens"
      ],
      "metadata": {
        "id": "Tn-7NIprENF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply preprocessing functions to train data\n",
        "tokenize(train_data, 'Tweet', 'stem_tokens')\n",
        "remove_URL_tokens(train_data, 'stem_tokens')\n",
        "convert_lowercase(train_data, 'stem_tokens')\n",
        "remove_special_char(train_data, 'stem_tokens')\n",
        "remove_empty_tokens(train_data, 'stem_tokens')\n",
        "stem_tokens(train_data, 'stem_tokens')\n",
        "remove_stopwords(train_data, 'stem_tokens')"
      ],
      "metadata": {
        "id": "XTG4h-Kb5Qau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply preprocessing functions to test data\n",
        "tokenize(test_data, 'Tweet', 'stem_tokens')\n",
        "remove_URL_tokens(test_data, 'stem_tokens')\n",
        "convert_lowercase(test_data, 'stem_tokens')\n",
        "remove_special_char(test_data, 'stem_tokens')\n",
        "remove_empty_tokens(test_data, 'stem_tokens')\n",
        "stem_tokens(test_data, 'stem_tokens')\n",
        "remove_stopwords(test_data, 'stem_tokens')"
      ],
      "metadata": {
        "id": "HKAbYPhsD3IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use of CountVectorizer"
      ],
      "metadata": {
        "id": "hCHX-YT6qz-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate labels from features, converting to numpy arrays\n",
        "X_train, y_train = train_data['stem_tokens'].to_numpy(), train_data['Sentiment'].to_numpy()\n",
        "X_test, y_test = test_data['stem_tokens'].to_numpy(), test_data['Sentiment'].to_numpy()\n",
        "\n",
        "#override function\n",
        "def override_fcn(doc):\n",
        "  # We expect a list of tokens as input\n",
        "  return doc\n",
        "\n",
        "# Count Vectorizer\n",
        "count_vec = CountVectorizer(\n",
        "    analyzer='word',\n",
        "    tokenizer= override_fcn,\n",
        "    preprocessor= override_fcn,\n",
        "    token_pattern= None,\n",
        "    max_features = 1000)\n",
        "\n",
        "# Fit training data using CountVectorizer\n",
        "counts_train = count_vec.fit_transform(X_train)\n",
        "print(counts_train.toarray())\n",
        "# Fit test data using CountVectorizer\n",
        "counts_test = count_vec.transform(X_test)\n",
        "print(counts_test.toarray())\n",
        "\n",
        "# Print the names of each of the features (1000 total))\n",
        "print(\"Length of vocabulary: \", len(count_vec.vocabulary_))\n",
        "# Print this mapping as dictionary\n",
        "print(count_vec.vocabulary_)\n",
        "\n",
        "## Which row represents 'great'\n",
        "print('\\nGreat is located at row: ',count_vec.vocabulary_['great'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3uP4SKqDqJi",
        "outputId": "03abb6e9-f0e8-42f9-9a5e-c9b3d0a07249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [2 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Length of vocabulary:  1000\n",
            "{'b': 92, 'russian': 721, 'use': 910, 'chemic': 165, 'weapon': 940, 'now': 582, 'ukrain': 878, 'aviat': 87, 'ha': 371, 'ukrainian': 890, 'report': 703, 'command': 187, 'air': 34, 'forc': 340, 'dure': 269, 'day': 228, 'defens': 236, 'shot': 762, 'three': 846, 'occup': 588, 'lesiavasylenko': 478, 'how': 399, 'know': 460, 'mani': 506, 'all': 37, 'thi': 838, 'hate': 375, 'violenc': 921, 'happen': 374, 'russia': 719, 'commit': 189, 'warcrim': 932, 'democraci': 241, 'must': 546, 'unit': 898, 'save': 735, 'world': 965, 'peacekeep': 623, 'mission': 532, 'there': 834, 'no': 573, 'other': 608, 'way': 938, 'children': 167, 'women': 959, 'journalist': 447, 'need': 554, 'us': 906, 'govern': 365, 'move': 542, 'rhetor': 711, 'action': 20, 'standwithukrain': 794, 'stopputin': 802, 'noflyzoneua': 576, 'intern': 428, 'crimin': 220, 'court': 214, 'ani': 54, 'member': 519, 'public': 664, 'may': 512, 'evid': 303, 'possibl': 640, 'war': 931, 'crime': 218, 'human': 401, 'veri': 915, 'interest': 427, 'polit': 637, 'current': 224, 'conflict': 203, 'thereidout': 835, 'putinisawarcrimin': 670, 'find': 330, 'most': 540, 'support': 814, 'invas': 430, 'come': 185, 'peopl': 625, 'live': 489, 'state': 797, 'land': 466, 'run': 718, 'militari': 526, 'not': 580, 'surpris': 816, 'just': 448, 'worth': 968, 'joebiden': 442, 'can': 159, 'help': 381, 'make': 504, 'give': 359, 'onli': 602, 'reason': 688, 'would': 970, 'defenc': 234, 'effect': 273, 'thing': 839, 'also': 45, 'more': 539, 'missil': 531, 'putinhitl': 669, 'share': 758, 'same': 731, 'posit': 639, 'face': 314, 'such': 811, 'home': 391, 'won': 960, 'stay': 798, 'kid': 454, 'starv': 796, 'death': 231, 'danger': 227, 'food': 339, 'water': 937, 'pleas': 632, 'keep': 450, 'fight': 327, 'nt': 584, 're': 681, 'right': 713, 'behind': 111, 'putin': 668, 'hell': 380, 'bad': 96, 'guy': 370, 'urgent': 905, 'time': 850, 'josepborrellf': 446, 'potu': 643, 'olafscholz': 597, 'ba': 94, 's': 725, 'attent': 85, 'turn': 872, '500daysoftigraygenocid': 11, 'unleash': 900, 'ethiopian': 288, 'eritrean': 285, 'unimped': 896, 'xe2x80x9cinjustic': 986, 'anywher': 64, 'threat': 845, 'justic': 449, 'everywher': 302, 'when': 948, 'will': 954, 'compass': 195, 'extend': 312, 'innoc': 422, 'civilian': 175, 'tigray': 847, 'icc': 408, 'unocha': 902, 'offic': 594, 'wa': 927, 'involv': 432, 'train': 865, 'terrorist': 829, 'group': 368, 'work': 963, 'liber': 480, 'nationalist': 550, 'nn': 570, 'someon': 780, 'fuck': 350, 'johnson': 443, 'person': 627, 'pm': 633, 'corrupt': 208, 'arriv': 77, 'palestin': 615, 'yemen': 994, 'syria': 819, 'afghanistan': 27, 'countri': 213, 'twitter': 874, 'block': 129, 'post': 641, 'video': 919, 'show': 764, 'suffer': 812, 'ppl': 645, 'worri': 966, 'compani': 192, 'polici': 636, 'everyth': 301, 'allow': 41, 'n': 547, 'tigraygenocid': 849, 'mrsorokaa': 543, 'win': 955, 'xf0x9fx87xbaxf0x9fx87xa6': 989, 'thread': 844, 'whi': 950, 'go': 361, 'almost': 42, 'month': 537, '100': 2, 'kill': 457, '3': 7, 'million': 528, 'refuge': 692, 'lost': 495, 'citi': 173, 'where': 949, 'visit': 922, 'everi': 298, 'few': 325, 'away': 89, 'left': 477, 'die': 249, 'sent': 751, 'noth': 581, 'want': 930, 'talk': 823, 'peac': 622, 'so': 777, 'foxnew': 344, 'say': 737, 'border': 132, 'open': 603, 'quiet': 675, 'see': 746, 'kyivindepend': 465, 'mayb': 513, 'china': 168, 'some': 779, 'sanction': 733, 'pay': 621, 'import': 415, 'chines': 169, 'good': 363, 'eu': 289, 'might': 524, 'start': 795, 'bundeskanzl': 148, 'least': 475, 'close': 179, 'shelter': 760, 'european': 292, 'valu': 911, 'one': 601, 'defend': 235, 'freedom': 346, 'hi': 384, 'putinswar': 671, 'zelenski': 996, 'cia': 172, 'soldier': 778, 'europ': 291, 'play': 631, 'big': 121, 'role': 716, 'build': 146, 'buy': 150, 'ga': 353, 'prepar': 647, 'destroy': 247, 'eu_commiss': 290, 'get': 358, 'could': 211, 'donxe2x80x99t': 265, 'let': 479, 'anyon': 61, 'life': 482, 'real': 685, 'elonmusk': 276, 'told': 854, 'dont': 264, 'write': 971, 'side': 765, 'kind': 458, 'nobodi': 574, 'prize': 654, 'regim': 695, 'today': 852, 'alli': 39, 'eye': 313, 'bputin': 137, 'canxe2x80x99t': 160, 'fli': 335, 'zone': 999, 'leader': 473, 'around': 76, 'fear': 321, 'ca': 155, 'impos': 416, 'famili': 318, 'declar': 232, 'oppos': 605, 'overshadow': 611, 'atroc': 82, 'manmad': 507, 'famin': 319, 'tigrayan': 848, 'fallen': 317, 'victim': 917, '500day': 10, 'ic': 407, 'speak': 786, 'stand': 793, 'vickyford': 916, 'ukun_newyork': 892, 'niinisto': 569, 'nazi': 552, 'complet': 197, 'jew': 440, 'break': 138, 'strong': 809, 'tank': 824, 'ball': 97, 'school': 740, 'r': 678, 'amp': 52, 'like': 483, 'becaus': 106, 'nato': 551, 'equip': 283, 'messag': 523, 'send': 750, 'far': 320, 'borisjohnson': 134, 'back': 95, 'hand': 373, 'take': 821, 'watch': 936, 'night': 568, 'promis': 659, 'voic': 923, 'w': 926, 'love': 497, 'lord': 493, 'law': 472, 'scheme': 739, 'near': 553, 'bit': 126, 'provid': 663, 'cover': 215, 'complic': 198, 'mass': 510, 'written': 972, 'neighbour': 557, 'popul': 638, 'cultur': 223, 'prevent': 651, 'friend': 348, 'enemi': 280, 'xd0x9cxd0xb0xd1x80xd1x96xd1x83xd0xbfxd0xbexd0xbbxd1x8c': 980, 'xd0x9axd0xb8xd1x97xd0xb2': 978, 'xd0x9bxd1x8cxd0xb2xd1x96xd0xb2': 979, 'xd1x85xd0xb0xd1x80xd0xbaxd1x96xd0xb2n': 982, 'xd0xa3xd0xbaxd1x80xd0xb0xd1x97xd0xbdxd0xb0': 981, 'closetheskyn': 180, 'noflyzon': 575, 'nuclear': 585, 'terror': 828, 'warn': 935, 'america': 49, 'lose': 494, 'heart': 379, 'bthe': 144, 'arm': 73, 'believ': 114, 'offens': 592, 'biden': 118, 'zelenskyyua': 998, 'protect': 662, 'step': 799, 'humanitarian': 402, 'aid': 33, 'assist': 80, 'bwhen': 153, 'took': 856, 'men': 521, 'too': 855, 'remov': 700, 'put': 667, 'top': 858, 'ukrainerussianwar': 885, 'iaponomarenko': 406, 'money': 536, '10': 1, 'dollar': 260, 'head': 377, 'ukrainewar': 888, 'weak': 939, 'saturday': 734, 'thought': 842, 'quot': 677, 'still': 800, 'busi': 149, 'ukrainen': 882, 'boycottrussia': 136, 'continu': 205, 'focu': 336, 'silent': 767, 'recognis': 690, 'hold': 389, 'abiyahmedali': 14, 'account': 17, 'bring': 141, 'end': 279, 'ungeneva': 895, 'blood': 130, 'holocaustmemorialday': 390, 'mlk': 534, 'grenfelltow': 367, 'blacklivesmatt': 128, 'bidenharri': 119, 'oprahmeghanharri': 606, 'reparationsnow': 701, 'kyiv': 464, 'mariupol': 509, 'zelenskyy': 997, 'kharkiv': 451, 'odessa': 590, 'kramatorsk': 461, 'think': 840, 'should': 763, 'tri': 867, 'stop': 801, 'oil': 596, 'atleast': 81, 'five': 333, 'usa': 909, 'year': 993, 'everchoos': 297, 'drive': 266, 'monthpl': 538, 'spread': 789, 'word': 962, 'asap': 78, 'trend': 866, 'even': 294, 'ridicul': 712, 'comparison': 194, 'own': 612, 'nnwe': 572, 'chang': 164, 'small': 776, 'better': 116, 'b031922': 93, 'dod': 257, 'thejointstaff': 832, 'secdef': 744, 'us_eucom': 907, 'odnigov': 591, 'whnsc': 951, 'us_stratcom': 908, 'hyperson': 405, 'warehous': 933, 'ammunit': 51, 'confirm': 202, 'compar': 193, 'resist': 707, 'uk': 877, 'vote': 924, 'brexit': 139, 'order': 607, 'yet': 995, 'care': 162, 'much': 544, 'advis': 25, 'invad': 429, 'bomb': 131, 'etc': 287, 'ask': 79, 'doesnxe2x80x99t': 259, 'doe': 258, 'bwe': 151, 'offer': 593, 'listen': 486, 'never': 560, 'un': 893, 'half': 372, 'recent': 689, 'abandon': 13, 'foreign': 341, 'feder': 322, 'than': 830, 'citizen': 174, 'seek': 747, 'evacu': 293, 'said': 730, 'gener': 355, 'nation': 549, 'control': 206, 'claim': 176, 'tragedi': 864, 'bi': 117, 'ssu': 791, 'activ': 21, 'minist': 530, '30': 8, 'economi': 272, 'power': 644, 'm': 499, 'wife': 953, 'remind': 699, 'anoth': 58, 'wrong': 973, 'intellig': 426, 'beauti': 105, 'readi': 684, 'leav': 476, 'exampl': 306, 'warinukrain': 934, 'sign': 766, 'march': 508, 'concern': 199, 've': 913, 'resid': 706, 'unitedst': 899, 'launder': 471, 'vp': 925, 'knew': 459, 'befor': 108, 'elect': 275, 'trump': 869, 'lie': 481, 'simpli': 769, 'poland': 635, 'germani': 357, 'bif': 120, '1': 0, 'neonazi': 558, 'russiaukrainewar': 724, 'bwhat': 152, 'els': 277, 'understand': 894, 'deal': 230, 'mean': 515, 'answer': 59, 'alway': 47, 'hope': 395, 'hrw': 400, 'line': 485, 'media': 517, 'econom': 271, 'pressur': 649, 'murder': 545, 'plan': 629, 'direct': 252, 'join': 445, 'act': 19, 'ever': 296, 'innasovsun': 421, 'well': 944, 'updat': 904, 'inform': 420, 'littl': 488, 'lot': 496, 'launch': 470, 'attack': 83, 'soon': 782, 'seem': 748, 'set': 754, 'here': 382, 'folk': 337, 'oligarch': 600, 'mcfaul': 514, 'bridg': 140, 'beg': 109, 'israel': 433, 'document': 256, 'exactli': 305, 'victori': 918, 'kiev': 456, 'themselv': 833, 'sever': 755, 'fire': 331, 'rocket': 715, 'system': 820, 'west': 945, 'long': 491, '20': 5, 'wwii': 976, 'wwiii': 977, 'mad': 500, 'ixe2x80x99m': 437, 'sure': 815, 'itxe2x80x99': 436, 'becom': 107, 'istandwithukrain': 435, 'xf0x9fx87xbaxf0x9fx87xb8': 990, 'covert': 216, 'street': 807, '2': 4, 'prez': 652, 'each': 270, '2000': 6, 'xf0x9fx87xb7xf0x9fx87xba': 988, 'dead': 229, 'creat': 217, 'follow': 338, 'comment': 188, 'differ': 250, 'milit': 525, 'azov': 91, 'battalion': 101, 'facil': 315, 'diplomat': 251, 'western': 946, 'select': 749, 'demonstr': 243, 'toward': 862, 'matter': 511, 'chief': 166, 'staff': 792, 'includ': 417, 'enough': 282, 'wheat': 947, 'basic': 100, 'product': 656, 'next': 564, 'ukrainerussiawar': 886, 'ukraineunderattack': 887, 'rais': 680, 'wsj': 974, 'wo': 958, 'base': 99, 'idea': 409, 'olex_scherba': 599, 'armenia': 74, 'express': 311, 'offici': 595, 'clear': 178, 'parti': 618, 'bbcnew': 102, 'deserv': 245, 'bwhi': 154, 'black': 127, 'sea': 741, 'both': 135, 'camp': 158, 'crimea': 219, 'properti': 661, 'illeg': 411, 'place': 628, 'demand': 239, 'alreadi': 44, 'independ': 418, 'allianc': 40, 'meanwhil': 516, 'expect': 310, 'invit': 431, 'xf0x9fx87xaaxf0x9fx87xba': 987, 'nnbut': 571, 'clown': 181, 'russianinvas': 722, 'free': 345, 'made': 501, 'belarusian': 113, 'embassi': 278, 'last': 468, 'cross': 222, 'quit': 676, 'evil': 304, 'realli': 687, 'overal': 610, 'color': 183, 'latest': 469, 'repres': 704, 'oper': 604, 'hostag': 396, 'hous': 398, 'shoot': 761, 'presid': 648, 'week': 942, 'meet': 518, 'perhap': 626, 'lviv': 498, 'along': 43, 'bthere': 145, 'great': 366, 'ambassador': 48, 'tori': 860, 'disgrac': 253, 'shame': 757, 'commun': 190, 'desir': 246, 'ignor': 410, 'call': 157, 'russiainvadedukrain': 720, 'stopputinnow': 803, 'unman': 901, 'aerial': 26, 'vehicl': 914, 'fighter': 328, 'condemn': 200, 'flag': 334, 'ufclondon': 876, 'instead': 424, 'exist': 308, '4': 9, 'expand': 309, 'refus': 693, 'safe': 728, 'thousand': 843, 'occupi': 589, 'donetsk': 263, 'administr': 23, 'daili': 226, 'imagin': 412, 'feel': 323, 'wonder': 961, 'though': 841, 'forget': 342, 'risk': 714, 'defeat': 233, 'caa': 156, 'strength': 808, 'deploy': 244, '8th': 12, 'combat': 184, 'bbut': 104, 'got': 364, 'wait': 928, 'cost': 210, 'problem': 655, 'corridor': 207, 'sumi': 813, 'territori': 827, 'energi': 281, 'democrat': 242, 'attempt': 84, 'look': 492, 'neutral': 559, 'aggress': 30, 'whole': 952, 'besid': 115, 'bigger': 122, 'fund': 352, 'pentagon': 624, 'simpl': 768, 'nrep': 583, 'arizona': 72, 'north': 579, 'thank': 831, 'full': 351, 'largest': 467, 'deliv': 238, 'either': 274, 'accept': 16, 'stoprussia': 804, 'mother': 541, 'news': 562, 'comfort': 186, 'putinwarcrimin': 673, 'surrend': 817, 'tweet': 873, 'pray': 646, 'anders_aslund': 53, 'belaru': 112, 'major': 503, 'event': 295, 'drop': 267, 'excus': 307, 'surviv': 818, 'tool': 857, 'anim': 55, 'situat': 773, 'unprovok': 903, 'strang': 806, 'potenti': 642, 'cossack': 209, 'total': 861, 'old': 598, 'part': 617, 'anyth': 62, '13': 3, 'hour': 397, 'wors': 967, 'xd8xb1xd9x88xd8xb3xd9x8axd8xa7': 983, 'special': 787, 'baltic': 98, 'respond': 708, 'red': 691, 'alert': 36, 'siren': 771, 'sound': 784, 'min': 529, 'russiaukraineconflict': 723, 'ww3': 975, 'india': 419, 'fact': 316, 'bbcworld': 103, 'u': 875, 'cohort': 182, 'hatecrim': 376, 'az': 90, 'lil': 484, 'kremlin': 462, 'kidnap': 455, 'modern': 535, 'communist': 191, 'valuestact': 912, 'demilitar': 240, 'abov': 15, 'honest': 392, 'xf0x9fx87xbaxf0x9fx87xb8attorneygener': 991, 'kremlinrussia_': 463, 'wear': 941, 'reach': 682, 'insid': 423, 'someth': 781, 'heard': 378, 'freeukrain': 347, 'rememb': 698, 'sad': 727, 'bori': 133, 'field': 326, 'high': 385, 'especi': 286, 'britain': 142, 'ukrainecrisi': 880, 'sinc': 770, 'intel': 425, 'captur': 161, 'point': 634, 'guarante': 369, 'republ': 705, 'anti': 60, 'first': 332, 'spring': 790, 'ukrainexf0x9fx87xbaxf0x9fx87xa6': 889, 'worthless': 969, 'stupid': 810, 'forward': 343, 'gave': 354, 'johnsonout54': 444, 'nice': 566, 'bso': 143, 'normal': 578, 'paper': 616, 'outrag': 609, 'toppl': 859, 'fellow': 324, 'hunterbidenslaptop': 403, 'within': 956, 'togeth': 853, 'alleg': 38, 'target': 825, 'caus': 163, 'pain': 614, 'approv': 70, 'rule': 717, 'constitut': 204, 'pass': 619, 'secur': 745, 'ukrainerussia': 884, 'anyway': 63, 'putinwarcrim': 672, 'local': 490, 'american': 50, 'push': 666, 'ni': 565, 'advanc': 24, 'istandwithrussia': 434, 'view': 920, 'anonym': 57, 'genocid': 356, 'histori': 386, 'hit': 387, 'ukraineinvas': 881, 'slavaukraini': 774, 'distract': 255, 'xe2x80x98': 984, 'kherson': 452, 'worker': 964, 'across': 18, 'japsonfrank': 438, 'jessel36': 439, 'honzou': 394, 'truth': 870, 'aka': 35, 'without': 957, 'plane': 630, 'railway': 679, 'announc': 56, 'tell': 826, 'sec': 742, 'nwho': 587, 'ukraineconflict': 879, 'argument': 71, 'choic': 170, 's400': 726, 'respons': 709, 'realiz': 686, 'avoid': 88, 'front': 349, 'theyxe2x80x99r': 837, 'taken': 822, 'hitler': 388, 'given': 360, 'due': 268, 'read': 683, 'samramani2': 732, 'council': 212, 'troop': 868, 'turkey': 871, 'final': 329, 'immedi': 413, 'remain': 697, 'past': 620, 'aggressor': 31, 'armi': 75, 'compet': 196, 'africa': 28, 'african': 29, 'bin': 125, 'result': 710, 'implement': 414, 'app': 66, 'servic': 753, 'conduct': 201, 'regard': 694, 'thermobar': 836, 'saw': 736, 'region': 696, 'shell': 759, 'town': 863, 'union': 897, 'donat': 261, 'equival': 284, 'welcom': 943, 'god': 362, 'pull': 665, 'nor': 577, 'appli': 68, 'membership': 520, 'speech': 788, 'alsoxc2xa0': 46, 'delay': 237, 'militarili': 527, 'done': 262, 'secblinken': 743, 'maid': 502, 'sit': 772, 'safeti': 729, 'repeat': 702, 'propaganda': 660, 'xe2x80x9c': 985, 'cut': 225, 'bukovina': 147, 'averag': 86, 'sleep': 775, 'mention': 522, 'soul': 783, 'ukrainenn': 883, 'na': 548, 'neighbor': 556, 'adamkinzing': 22, 'question': 674, 'appear': 67, 'new': 561, 'wake': 929, 'mistak': 533, 'kick': 453, 'begin': 110, 'everyon': 300, 'jewish': 441, 'project': 658, 'leadership': 474, 'program': 657, 'serious': 752, 'approach': 69, 'man': 505, 'nickiminaj': 567, 'crisi': 221, 'biggest': 123, 'ye': 992, 'pretti': 650, 'agre': 32, 'liter': 487, 'negoti': 555, 'billion': 124, 'destruct': 248, 'price': 653, 'hurt': 404, 'christ': 171, 'ukranian': 891, 'disinform': 254, 'stori': 805, 'hesit': 383, 'nuke': 586, 'soviet': 785, 'shall': 756, 'nex': 563, 'scare': 738, 'p': 613, 'ap': 65, 'cleans': 177, 'everyday': 299, 'tinxe2x80x99': 851, 'honor': 393}\n",
            "\n",
            "Great is located at row:  366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the Naive Bayes model to our training data\n",
        "nb = MultinomialNB()\n",
        "# Fit model to training data (default alpha = 1 has Laplace smoothing)\n",
        "nb.fit(counts_train.toarray(), y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_preds_test = nb.predict(counts_test.toarray())\n",
        "\n",
        "# Predict on train data\n",
        "y_preds_train = nb.predict(counts_train.toarray())\n",
        "\n",
        "#Print test/train accuracy\n",
        "print('Test accuracy with simple Naive Bayes:',accuracy_score(y_test,y_preds_test))\n",
        "print('Training accuracy with simple Naive Bayes:',accuracy_score(y_train,y_preds_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ9Y9I6qDhPm",
        "outputId": "a17a474e-0d0f-4937-a2b7-9b406cda540b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes: 0.7055555555555556\n",
            "Training accuracy with simple Naive Bayes: 0.8533969010727056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use of TF-IDF-Vectorizer"
      ],
      "metadata": {
        "id": "0YOg5bnXq81O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that smoothing is done by default\n",
        "tfidf = TfidfTransformer()\n",
        "\n",
        "#fit transform train data\n",
        "tfs_train = tfidf.fit_transform(counts_train)\n",
        "#fit transform test data\n",
        "tfs_test = tfidf.transform(counts_test)\n",
        "\n",
        "# Use the TFIDF counts for modelling\n",
        "X_train = tfs_train.toarray()\n",
        "X_test = tfs_test.toarray()"
      ],
      "metadata": {
        "id": "LUZb3-pmEJql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the Naive Bayes model to our training data\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# Fit model to training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_preds_test = nb.predict(X_test)\n",
        "\n",
        "# Predict on train data\n",
        "y_preds_train = nb.predict(X_train)\n",
        "\n",
        "#print test/train accuracy\n",
        "print('Test accuracy with simple Naive Bayes:',accuracy_score(y_test,y_preds_test))\n",
        "print('Training accuracy with simple Naive Bayes:',accuracy_score(y_train,y_preds_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlzuoftxEUlV",
        "outputId": "099c5691-e0fb-4e67-b281-83f456b5c5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with simple Naive Bayes: 0.7388888888888889\n",
            "Training accuracy with simple Naive Bayes: 0.8462455303933254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performance Evaluation"
      ],
      "metadata": {
        "id": "xCOHbSeY5Qv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC curve"
      ],
      "metadata": {
        "id": "6d1SagDzxtHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predict y probabilities using X_test features\n",
        "y_preds_test_prob = nb.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "zx2phZ1BulTJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#index the inner matrix and retrieve the second item of each list (probability of y to be 1)\n",
        "new_y_pred_test = y_preds_test_prob[:,1]"
      ],
      "metadata": {
        "id": "IXVHEIwMu-N9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot ROC curve\n",
        "\n",
        "#imports\n",
        "from sklearn.metrics import *\n",
        "\n",
        "#compute false positive,true positive rates, \n",
        "fpr, tpr, thresholds = roc_curve(y_test, new_y_pred_test, \n",
        "                                 pos_label = 1)\n",
        "\n",
        "#compute area under ROC curve\n",
        "auroc = roc_auc_score(y_test, new_y_pred_test)\n",
        "\n",
        "#create the plot\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve of Sentiment Modeling: ' + str(round(auroc,5)))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pTJRP1RH5Ywb",
        "outputId": "d134353d-ea18-460c-e81f-7220e5c6fa7a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "Rz_UFk3frvcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standard threshold\n",
        "as_threshold = 0.5 \n",
        "\n",
        "# for test prediction results above threshold\n",
        "as_dich_pred = (y_preds_test > as_threshold).astype(int)\n",
        "as_dich_true = y_test\n",
        "\n",
        "## computes accuracy\n",
        "as_acc = accuracy_score(as_dich_true, as_dich_pred)\n",
        "\n",
        "## confusion matrix\n",
        "c_mat = confusion_matrix(as_dich_true, as_dich_pred)\n",
        "\n",
        "#change two dimensional array into flattened array\n",
        "TN, FP, FN, TP = c_mat.ravel()\n",
        "\n",
        "\n",
        "print(\"Sentiment Model\")\n",
        "print(\"Accuracy: \" + str(round(as_acc, 2)))\n",
        "print(\"True positives: \" + str(round(TP)))\n",
        "print(\"True negatives: \" + str(round(TN)))\n",
        "print(\"False positives: \" + str(round(FP)))\n",
        "print(\"False negatives: \" + str(round(FN)))\n",
        "\n",
        "print(\"Confusion matrix\")\n",
        "print(c_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0wSfABK9uli",
        "outputId": "34c55159-5f0e-4403-b6cd-d707d5c05959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asthma model\n",
            "Accuracy: 0.74\n",
            "True positives: 43\n",
            "True negatives: 223\n",
            "False positives: 13\n",
            "False negatives: 81\n",
            "Confusion matrix\n",
            "[[223  13]\n",
            " [ 81  43]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compute Recall/Specificity/Precision"
      ],
      "metadata": {
        "id": "_P8emDcZr197"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute metrics\n",
        "as_sens = TP/(TP + FN)\n",
        "as_spec = TN/(TN + FP)\n",
        "as_prec = TP/(TP + FP)\n",
        "  \n",
        "print(\"Sensitivity (Recall): \" + str(round(as_sens, 2)))\n",
        "print(\"Specificity: \" + str(round(as_spec, 2)))\n",
        "print(\"Precision: \" + str(round(as_prec, 2)))"
      ],
      "metadata": {
        "id": "R8Ut_JKf-ga6",
        "outputId": "bac0fe79-7de8-4d95-a2d0-cea1117146bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensitivity (Recall): 0.35\n",
            "Specificity: 0.94\n",
            "Precision: 0.77\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Part II: Having fun with NLP using the Twitter API.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}